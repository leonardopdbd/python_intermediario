{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "> Projeto Desenvolve <br>\nProgramação Intermediária com Python <br>\nProfa. Camila Laranjeira (mila@projetodesenvolve.com.br) <br>\n\n# 3.6 - Pandas",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Exercícios\nAntes de continuar, baixe os arquivos das bases de dados de partidas em Copas do Mundo e salve na mesma pasta deste notebook.\n* https://raw.githubusercontent.com/camilalaranjeira/python-intermediario/main/fifa-wc/matches_1930_2022.csv\n* https://raw.githubusercontent.com/camilalaranjeira/python-intermediario/main/fifa-wc/matches_1991_2023.csv\n\nA célula a seguir já carrega os dados em CSV e ajusta as colunas para trabalharmos com os nomes traduzidos (como fizemos em aula).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\npd.set_option('display.max_columns',None)\npd.set_option('display.max_rows',12)\n\nwcwomen_df = pd.read_csv('matches_1991_2023.csv')\nwcmen_df   = pd.read_csv('matches_1930_2022.csv')\nwc = pd.concat((wcwomen_df,wcmen_df)).reset_index()\n\nnomes_traduzidos = {'home_team': 'time_1', 'away_team': 'time_2', 'home_score': 'gols_1', 'away_score': 'gols_2',\n                    'Date': 'data', 'Year': 'ano', 'Host': 'país_sede', 'Attendance': 'comparecimento',\n                    'Score': 'resultado', 'Round': 'rodada', 'home_goal': 'gols_1_detalhes', 'away_goal': 'gols_2_detalhes',\n                    'home_own_goal': 'gols_1_contra', 'away_own_goal': 'gols_2_contra',\n                    'home_penalty_goal': 'gols_1_penalti', 'away_penalty_goal': 'gols_2_penalti',\n                    'home_red_card': 'cartao_vermelho_1', 'away_red_card': 'cartao_vermelho_2',\n                    'home_yellow_card_long': 'cartao_amarelo_1', 'away_yellow_card_long': 'cartao_amarelo_2'}\n\nwc = wc.loc[:, nomes_traduzidos.keys()]\nwc.columns = nomes_traduzidos.values()\n\ncopa = wc['ano'].apply( lambda x: 'Masculina' if x % 2 == 0 else 'Feminina').astype('string')\nwc['copa'] = copa\ndisplay(wc)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Q1.\nFaça as conversões de tipo necessárias para que a saída do comando `wc.info()` seja como apresentado a seguir. E **salve o novo dataframe** com o comando `df.to_csv('wc_formatado.csv')`.\n\n```\nData columns (total 21 columns):\n #   Column             Non-Null Count  Dtype         \n---  ------             --------------  -----         \n 0   time_1             1312 non-null   string        \n 1   time_2             1312 non-null   string        \n 2   gols_1             1312 non-null   int64         \n 3   gols_2             1312 non-null   int64         \n 4   data               1312 non-null   datetime64[ns]\n 5   ano                1312 non-null   int64         \n 6   país_sede          1312 non-null   string        \n 7   comparecimento     1312 non-null   int64         \n 8   resultado          1312 non-null   string        \n 9   rodada             1312 non-null   category      \n 10  gols_1_detalhes    970 non-null    string        \n 11  gols_2_detalhes    771 non-null    string        \n 12  gols_1_contra      57 non-null     string        \n 13  gols_2_contra      30 non-null     string        \n 14  gols_1_penalti     170 non-null    string        \n 15  gols_2_penalti     119 non-null    string        \n 16  cartao_vermelho_1  59 non-null     string        \n 17  cartao_vermelho_2  65 non-null     string        \n 18  cartao_amarelo_1   834 non-null    string        \n 19  cartao_amarelo_2   857 non-null    string        \n 20  copa               1312 non-null   string \n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\n# Definir opções de visualização\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 12)\n\n# Carregar os dados\nwcwomen_df = pd.read_csv('matches_1991_2023.csv')\nwcmen_df = pd.read_csv('matches_1930_2022.csv')\n\n# Concatenar os dataframes\nwc = pd.concat((wcwomen_df, wcmen_df)).reset_index()\n\n# Traduzir os nomes das colunas\nnomes_traduzidos = {'home_team': 'time_1', 'away_team': 'time_2', 'home_score': 'gols_1', 'away_score': 'gols_2',\n                    'Date': 'data', 'Year': 'ano', 'Host': 'país_sede', 'Attendance': 'comparecimento',\n                    'Score': 'resultado', 'Round': 'rodada', 'home_goal': 'gols_1_detalhes', 'away_goal': 'gols_2_detalhes',\n                    'home_own_goal': 'gols_1_contra', 'away_own_goal': 'gols_2_contra',\n                    'home_penalty_goal': 'gols_1_penalti', 'away_penalty_goal': 'gols_2_penalti',\n                    'home_red_card': 'cartao_vermelho_1', 'away_red_card': 'cartao_vermelho_2',\n                    'home_yellow_card_long': 'cartao_amarelo_1', 'away_yellow_card_long': 'cartao_amarelo_2'}\n\nwc = wc.loc[:, nomes_traduzidos.keys()]\nwc.columns = nomes_traduzidos.values()\n\n# Adicionar a coluna 'copa'\ncopa = wc['ano'].apply(lambda x: 'Masculina' if x % 2 == 0 else 'Feminina').astype('string')\nwc['copa'] = copa\n\n# Conversões de tipos de dados\nwc['time_1'] = wc['time_1'].astype('string')\nwc['time_2'] = wc['time_2'].astype('string')\nwc['gols_1'] = wc['gols_1'].astype('int64')\nwc['gols_2'] = wc['gols_2'].astype('int64')\nwc['data'] = pd.to_datetime(wc['data'])\nwc['ano'] = wc['ano'].astype('int64')\nwc['país_sede'] = wc['país_sede'].astype('string')\nwc['comparecimento'] = wc['comparecimento'].fillna(0).astype('int64')\nwc['resultado'] = wc['resultado'].astype('string')\nwc['rodada'] = wc['rodada'].astype('category')\nwc['gols_1_detalhes'] = wc['gols_1_detalhes'].astype('string')\nwc['gols_2_detalhes'] = wc['gols_2_detalhes'].astype('string')\nwc['gols_1_contra'] = wc['gols_1_contra'].astype('string')\nwc['gols_2_contra'] = wc['gols_2_contra'].astype('string')\nwc['gols_1_penalti'] = wc['gols_1_penalti'].astype('string')\nwc['gols_2_penalti'] = wc['gols_2_penalti'].astype('string')\nwc['cartao_vermelho_1'] = wc['cartao_vermelho_1'].astype('string')\nwc['cartao_vermelho_2'] = wc['cartao_vermelho_2'].astype('string')\nwc['cartao_amarelo_1'] = wc['cartao_amarelo_1'].astype('string')\nwc['cartao_amarelo_2'] = wc['cartao_amarelo_2'].astype('string')\n\n# Salvar o dataframe formatado em um novo arquivo CSV\nwc.to_csv('wc_formatado.csv', index=False)\n\n# Exibir as informações do dataframe\nwc.info()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-1-f071c77b6608>:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        },
        {
          "ename": "<class 'FileNotFoundError'>",
          "evalue": "[Errno 44] No such file or directory: 'matches_1991_2023.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Carregar os dados\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m wcwomen_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatches_1991_2023.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m wcmen_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatches_1930_2022.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Concatenar os dataframes\u001b[39;00m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 44] No such file or directory: 'matches_1991_2023.csv'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "#### Q2.\nApresente a linha do dataframe `wc` que corresponde ao jogo com maior audiência da história.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Encontrar o índice do jogo com maior audiência\nindice_maior_audiencia = wc['comparecimento'].idxmax()\n\n# Selecionar a linha correspondente\njogo_maior_audiencia = wc.loc[indice_maior_audiencia]\n\n# Exibir a linha correspondente\nprint(jogo_maior_audiencia)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Q3.\nAplicando operações sobre as colunas `ano` e `copa` do dataframe `wc`, apresente quantas copas femininas e quantas copas masculinas já aconteceram na história.\n\nExemplo de saída (valores inventados):\n```\nMasculina: 22\nFeminina: 9\n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Contar o número de copas por tipo (masculina e feminina)\ncontagem_copas = wc.groupby('copa')['ano'].nunique()\n\n# Exibir os resultados\nprint(f\"Masculina: {contagem_copas['Masculina']}\")\nprint(f\"Feminina: {contagem_copas['Feminina']}\")\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Q3. \nCrie um dataframe `participacao` com as colunas `país`, `copa`, e `num_copas` que armazena a quantidade de copas do mundo que cada país participou, informando se é da copa masculina ou feminina. Ao final imprima, como apresentado a seguir, o top 5 países de cada competição que mais participou de copas do mundo.\n\nExemplo de saída (valores inventados):\n```\npaís            copa        num_copas\nBrazil          Feminina    8\nUnites States   Feminina    8\nGermany         Feminina    8\nJapan           Feminina    7\nColombia        Feminina    7\n```\n\n```\npaís            copa        num_copas\nBrazil          Masculina   21\nGermany         Masculina   21\nArgentina       Masculina   20\nEngland         Masculina   20\nMexico          Masculina   20\n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Contar a participação de cada país por tipo de Copa\nparticipacao = (\n    wc[['time_1', 'copa', 'ano']]\n    .rename(columns={'time_1': 'país'})  # Renomear a coluna para 'país'\n    .drop_duplicates(subset=['país', 'ano', 'copa'])  # Remover duplicatas de país, ano e tipo de Copa\n    .groupby(['país', 'copa'])\n    .size()\n    .reset_index(name='num_copas')  # Adicionar coluna com o total de participações\n)\n\n# Separar os top 5 países de cada tipo de Copa\ntop_feminina = participacao[participacao['copa'] == 'Feminina'].nlargest(5, 'num_copas')\ntop_masculina = participacao[participacao['copa'] == 'Masculina'].nlargest(5, 'num_copas')\n\n# Exibir os resultados\nprint(\"Top 5 países na Copa do Mundo Feminina:\")\nprint(top_feminina)\n\nprint(\"\\nTop 5 países na Copa do Mundo Masculina:\")\nprint(top_masculina)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Q4. \n* Crie um dataframe `gols` com duas colunas `país` e `total_gols` com o total de gols marcados por cada país durante todas as copas do mundo, juntando gols em casa (`gols_1`) e gols como time visitante (`gols_2`).\n* Imprima o dataframe `gols` ordenado de forma decrescente, para que os times com mais gols fiquem no topo.\n\nSegue um exemplo ilustrativo com o formato do dataframe resultado:\n\n```\npaís        total_gols\nBrazil      120\nArgentina   112\nGermany     107\n...\n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Criar um dataframe com os gols como time da casa (gols_1)\ngols_casa = (\n    wc[['time_1', 'gols_1']]\n    .rename(columns={'time_1': 'país', 'gols_1': 'gols'})\n)\n\n# Criar um dataframe com os gols como time visitante (gols_2)\ngols_visitante = (\n    wc[['time_2', 'gols_2']]\n    .rename(columns={'time_2': 'país', 'gols_2': 'gols'})\n)\n\n# Concatenar os dois dataframes\ngols_total = pd.concat([gols_casa, gols_visitante])\n\n# Agrupar por país e somar os gols\ngols = gols_total.groupby('país')['gols'].sum().reset_index()\n\n# Renomear a coluna com o total de gols\ngols = gols.rename(columns={'gols': 'total_gols'})\n\n# Ordenar o dataframe em ordem decrescente de total_gols\ngols = gols.sort_values(by='total_gols', ascending=False).reset_index(drop=True)\n\n# Exibir o dataframe\nprint(gols)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Q5. \nQual país tomou mais cartões amarelos somando todas as copas?\n\nNeste exercício você vai trabalhar com as colunas `cartao_amarelo_1` e `cartao_amarelo_2` onde cada observação é uma string represetando uma lista dos cartões amarelos de um único jogo na forma `minuto|placar|jogador(a)`. Por exemplo:\n```\n['16’|1:0|Rosana Gómez', '20’|2:0|Gabriela Chávez]\n```\n\nRecomendo criar colunas `num_cartoes_1` e `num_cartoes_2` a partir de cada coluna `cartao_amarelo_X` usando o método genérico `apply` para chamar uma função que você vai criar para transformar uma observação de cartão amarelo em uma contagem de elementos da lista. \n\nLembre de levar em consideração que muitas observações são `NaN`. \n\nEm seguida faça sua mágica para agrupar as informações por país, acumular os cartões de jogos em casa e jogos visitante, e produzir o resultado final como apresentado a seguir (valores inventados):\n\n```\npaís        cartões amarelos\nArgentina   97\nEngland     93\nAustralia   93\n...\n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\n# Função para contar o número de cartões amarelos em uma observação\ndef contar_cartoes(cartoes):\n    if pd.isna(cartoes):  # Verificar se é NaN\n        return 0\n    return len(eval(cartoes))  # Avaliar a string como uma lista e contar os elementos\n\n# Criar colunas para contar os cartões amarelos de cada time\nwc['num_cartoes_1'] = wc['cartao_amarelo_1'].apply(contar_cartoes)\nwc['num_cartoes_2'] = wc['cartao_amarelo_2'].apply(contar_cartoes)\n\n# Criar dataframes para os cartões como time da casa e como visitante\ncartoes_casa = wc[['time_1', 'num_cartoes_1']].rename(columns={'time_1': 'país', 'num_cartoes_1': 'cartoes'})\ncartoes_visitante = wc[['time_2', 'num_cartoes_2']].rename(columns={'time_2': 'país', 'num_cartoes_2': 'cartoes'})\n\n# Concatenar os dataframes\ncartoes_total = pd.concat([cartoes_casa, cartoes_visitante])\n\n# Agrupar por país e somar os cartões\ncartoes_agrupados = cartoes_total.groupby('país')['cartoes'].sum().reset_index()\n\n# Renomear a coluna para o formato solicitado\ncartoes_agrupados = cartoes_agrupados.rename(columns={'cartoes': 'cartões_amarelos'})\n\n# Ordenar em ordem decrescente de cartões amarelos\ncartoes_agrupados = cartoes_agrupados.sort_values(by='cartões_amarelos', ascending=False).reset_index(drop=True)\n\n# Exibir o resultado\nprint(cartoes_agrupados)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Q6.\nQual o top10 jogadores com mais gols em copa? Considere gols em jogo e gols de pênalti.\n\nPara conseguir essa informação, você precisará trabalhar com as colunas:\n```\n10  gols_1_detalhes         \n11  gols_2_detalhes    \n14  gols_1_penalti     \n15  gols_2_penalti     \n```\n\nEssas também são colunas textuais, onde cada observações apresenta todos os gols de uma partida separados pelo caracter `|`. Cada gol está na forma `'Jogador(a) · minuto’'`. Por exemplo:\n```\n'Alex Morgan · 12’|Rose Lavelle · 20’'\n```\n\nLembre de levar em consideração que muitas observações são `NaN`. \n\nRecomendo criar um dicionário à parte, onde cada chave será um jogador encontrado nessas colunas do dataframe `wc` e o valor correspondente será a contagem de ocorrências desses nomes.\n\nEm seguida basta converter o seu dicionário em um dataframe e imprimí-lo na forma (valores não são inventados 😁):\n```\njogador(a)      num_gols \nMarta           17\nMiroslav Klose  16\n... \n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\n# Função para extrair nomes dos jogadores e contar gols\ndef extrair_gols(detalhes):\n    if pd.isna(detalhes):  # Verificar se é NaN\n        return []\n    gols = detalhes.split('|')  # Separar os gols pela barra vertical\n    jogadores = [gol.split(' · ')[0] for gol in gols]  # Extrair o nome do jogador(a)\n    return jogadores\n\n# Criar um dicionário para armazenar os gols\ngols_por_jogador = {}\n\n# Listar as colunas que contêm os detalhes dos gols\ncolunas_gols = ['gols_1_detalhes', 'gols_2_detalhes', 'gols_1_penalti', 'gols_2_penalti']\n\nfor coluna in colunas_gols:\n    wc[coluna] = wc[coluna].fillna('')  # Substituir NaN por string vazia\n    wc[coluna].apply(lambda x: [gols_por_jogador.update({jogador: gols_por_jogador.get(jogador, 0) + 1}) \n                                for jogador in extrair_gols(x)])\n\n# Converter o dicionário em um dataframe\ngols_df = pd.DataFrame(list(gols_por_jogador.items()), columns=['jogador(a)', 'num_gols'])\n\n# Ordenar em ordem decrescente pelo número de gols\ngols_df = gols_df.sort_values(by='num_gols', ascending=False).reset_index(drop=True)\n\n# Exibir o top 10 jogadores com mais gols\nprint(gols_df.head(10))\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}