{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "> Projeto Desenvolve <br>\nPrograma√ß√£o Intermedi√°ria com Python <br>\nProfa. Camila Laranjeira (mila@projetodesenvolve.com.br) <br>\n\n# 3.6 - Pandas",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Exerc√≠cios\nAntes de continuar, baixe os arquivos das bases de dados de partidas em Copas do Mundo e salve na mesma pasta deste notebook.\n* https://raw.githubusercontent.com/camilalaranjeira/python-intermediario/main/fifa-wc/matches_1930_2022.csv\n* https://raw.githubusercontent.com/camilalaranjeira/python-intermediario/main/fifa-wc/matches_1991_2023.csv\n\nA c√©lula a seguir j√° carrega os dados em CSV e ajusta as colunas para trabalharmos com os nomes traduzidos (como fizemos em aula).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\npd.set_option('display.max_columns',None)\npd.set_option('display.max_rows',12)\n\nwcwomen_df = pd.read_csv('matches_1991_2023.csv')\nwcmen_df   = pd.read_csv('matches_1930_2022.csv')\nwc = pd.concat((wcwomen_df,wcmen_df)).reset_index()\n\nnomes_traduzidos = {'home_team': 'time_1', 'away_team': 'time_2', 'home_score': 'gols_1', 'away_score': 'gols_2',\n                    'Date': 'data', 'Year': 'ano', 'Host': 'pa√≠s_sede', 'Attendance': 'comparecimento',\n                    'Score': 'resultado', 'Round': 'rodada', 'home_goal': 'gols_1_detalhes', 'away_goal': 'gols_2_detalhes',\n                    'home_own_goal': 'gols_1_contra', 'away_own_goal': 'gols_2_contra',\n                    'home_penalty_goal': 'gols_1_penalti', 'away_penalty_goal': 'gols_2_penalti',\n                    'home_red_card': 'cartao_vermelho_1', 'away_red_card': 'cartao_vermelho_2',\n                    'home_yellow_card_long': 'cartao_amarelo_1', 'away_yellow_card_long': 'cartao_amarelo_2'}\n\nwc = wc.loc[:, nomes_traduzidos.keys()]\nwc.columns = nomes_traduzidos.values()\n\ncopa = wc['ano'].apply( lambda x: 'Masculina' if x % 2 == 0 else 'Feminina').astype('string')\nwc['copa'] = copa\ndisplay(wc)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Q1.\nFa√ßa as convers√µes de tipo necess√°rias para que a sa√≠da do comando `wc.info()` seja como apresentado a seguir. E **salve o novo dataframe** com o comando `df.to_csv('wc_formatado.csv')`.\n\n```\nData columns (total 21 columns):\n #   Column             Non-Null Count  Dtype         \n---  ------             --------------  -----         \n 0   time_1             1312 non-null   string        \n 1   time_2             1312 non-null   string        \n 2   gols_1             1312 non-null   int64         \n 3   gols_2             1312 non-null   int64         \n 4   data               1312 non-null   datetime64[ns]\n 5   ano                1312 non-null   int64         \n 6   pa√≠s_sede          1312 non-null   string        \n 7   comparecimento     1312 non-null   int64         \n 8   resultado          1312 non-null   string        \n 9   rodada             1312 non-null   category      \n 10  gols_1_detalhes    970 non-null    string        \n 11  gols_2_detalhes    771 non-null    string        \n 12  gols_1_contra      57 non-null     string        \n 13  gols_2_contra      30 non-null     string        \n 14  gols_1_penalti     170 non-null    string        \n 15  gols_2_penalti     119 non-null    string        \n 16  cartao_vermelho_1  59 non-null     string        \n 17  cartao_vermelho_2  65 non-null     string        \n 18  cartao_amarelo_1   834 non-null    string        \n 19  cartao_amarelo_2   857 non-null    string        \n 20  copa               1312 non-null   string \n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\n# Definir op√ß√µes de visualiza√ß√£o\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 12)\n\n# Carregar os dados\nwcwomen_df = pd.read_csv('matches_1991_2023.csv')\nwcmen_df = pd.read_csv('matches_1930_2022.csv')\n\n# Concatenar os dataframes\nwc = pd.concat((wcwomen_df, wcmen_df)).reset_index()\n\n# Traduzir os nomes das colunas\nnomes_traduzidos = {'home_team': 'time_1', 'away_team': 'time_2', 'home_score': 'gols_1', 'away_score': 'gols_2',\n                    'Date': 'data', 'Year': 'ano', 'Host': 'pa√≠s_sede', 'Attendance': 'comparecimento',\n                    'Score': 'resultado', 'Round': 'rodada', 'home_goal': 'gols_1_detalhes', 'away_goal': 'gols_2_detalhes',\n                    'home_own_goal': 'gols_1_contra', 'away_own_goal': 'gols_2_contra',\n                    'home_penalty_goal': 'gols_1_penalti', 'away_penalty_goal': 'gols_2_penalti',\n                    'home_red_card': 'cartao_vermelho_1', 'away_red_card': 'cartao_vermelho_2',\n                    'home_yellow_card_long': 'cartao_amarelo_1', 'away_yellow_card_long': 'cartao_amarelo_2'}\n\nwc = wc.loc[:, nomes_traduzidos.keys()]\nwc.columns = nomes_traduzidos.values()\n\n# Adicionar a coluna 'copa'\ncopa = wc['ano'].apply(lambda x: 'Masculina' if x % 2 == 0 else 'Feminina').astype('string')\nwc['copa'] = copa\n\n# Convers√µes de tipos de dados\nwc['time_1'] = wc['time_1'].astype('string')\nwc['time_2'] = wc['time_2'].astype('string')\nwc['gols_1'] = wc['gols_1'].astype('int64')\nwc['gols_2'] = wc['gols_2'].astype('int64')\nwc['data'] = pd.to_datetime(wc['data'])\nwc['ano'] = wc['ano'].astype('int64')\nwc['pa√≠s_sede'] = wc['pa√≠s_sede'].astype('string')\nwc['comparecimento'] = wc['comparecimento'].fillna(0).astype('int64')\nwc['resultado'] = wc['resultado'].astype('string')\nwc['rodada'] = wc['rodada'].astype('category')\nwc['gols_1_detalhes'] = wc['gols_1_detalhes'].astype('string')\nwc['gols_2_detalhes'] = wc['gols_2_detalhes'].astype('string')\nwc['gols_1_contra'] = wc['gols_1_contra'].astype('string')\nwc['gols_2_contra'] = wc['gols_2_contra'].astype('string')\nwc['gols_1_penalti'] = wc['gols_1_penalti'].astype('string')\nwc['gols_2_penalti'] = wc['gols_2_penalti'].astype('string')\nwc['cartao_vermelho_1'] = wc['cartao_vermelho_1'].astype('string')\nwc['cartao_vermelho_2'] = wc['cartao_vermelho_2'].astype('string')\nwc['cartao_amarelo_1'] = wc['cartao_amarelo_1'].astype('string')\nwc['cartao_amarelo_2'] = wc['cartao_amarelo_2'].astype('string')\n\n# Salvar o dataframe formatado em um novo arquivo CSV\nwc.to_csv('wc_formatado.csv', index=False)\n\n# Exibir as informa√ß√µes do dataframe\nwc.info()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-1-f071c77b6608>:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        },
        {
          "ename": "<class 'FileNotFoundError'>",
          "evalue": "[Errno 44] No such file or directory: 'matches_1991_2023.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Carregar os dados\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m wcwomen_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatches_1991_2023.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m wcmen_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatches_1930_2022.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Concatenar os dataframes\u001b[39;00m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 44] No such file or directory: 'matches_1991_2023.csv'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "#### Q2.\nApresente a linha do dataframe `wc` que corresponde ao jogo com maior audi√™ncia da hist√≥ria.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Encontrar o √≠ndice do jogo com maior audi√™ncia\nindice_maior_audiencia = wc['comparecimento'].idxmax()\n\n# Selecionar a linha correspondente\njogo_maior_audiencia = wc.loc[indice_maior_audiencia]\n\n# Exibir a linha correspondente\nprint(jogo_maior_audiencia)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Q3.\nAplicando opera√ß√µes sobre as colunas `ano` e `copa` do dataframe `wc`, apresente quantas copas femininas e quantas copas masculinas j√° aconteceram na hist√≥ria.\n\nExemplo de sa√≠da (valores inventados):\n```\nMasculina: 22\nFeminina: 9\n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Contar o n√∫mero de copas por tipo (masculina e feminina)\ncontagem_copas = wc.groupby('copa')['ano'].nunique()\n\n# Exibir os resultados\nprint(f\"Masculina: {contagem_copas['Masculina']}\")\nprint(f\"Feminina: {contagem_copas['Feminina']}\")\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Q3. \nCrie um dataframe `participacao` com as colunas `pa√≠s`, `copa`, e `num_copas` que armazena a quantidade de copas do mundo que cada pa√≠s participou, informando se √© da copa masculina ou feminina. Ao final imprima, como apresentado a seguir, o top 5 pa√≠ses de cada competi√ß√£o que mais participou de copas do mundo.\n\nExemplo de sa√≠da (valores inventados):\n```\npa√≠s            copa        num_copas\nBrazil          Feminina    8\nUnites States   Feminina    8\nGermany         Feminina    8\nJapan           Feminina    7\nColombia        Feminina    7\n```\n\n```\npa√≠s            copa        num_copas\nBrazil          Masculina   21\nGermany         Masculina   21\nArgentina       Masculina   20\nEngland         Masculina   20\nMexico          Masculina   20\n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Contar a participa√ß√£o de cada pa√≠s por tipo de Copa\nparticipacao = (\n    wc[['time_1', 'copa', 'ano']]\n    .rename(columns={'time_1': 'pa√≠s'})  # Renomear a coluna para 'pa√≠s'\n    .drop_duplicates(subset=['pa√≠s', 'ano', 'copa'])  # Remover duplicatas de pa√≠s, ano e tipo de Copa\n    .groupby(['pa√≠s', 'copa'])\n    .size()\n    .reset_index(name='num_copas')  # Adicionar coluna com o total de participa√ß√µes\n)\n\n# Separar os top 5 pa√≠ses de cada tipo de Copa\ntop_feminina = participacao[participacao['copa'] == 'Feminina'].nlargest(5, 'num_copas')\ntop_masculina = participacao[participacao['copa'] == 'Masculina'].nlargest(5, 'num_copas')\n\n# Exibir os resultados\nprint(\"Top 5 pa√≠ses na Copa do Mundo Feminina:\")\nprint(top_feminina)\n\nprint(\"\\nTop 5 pa√≠ses na Copa do Mundo Masculina:\")\nprint(top_masculina)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Q4. \n* Crie um dataframe `gols` com duas colunas `pa√≠s` e `total_gols` com o total de gols marcados por cada pa√≠s durante todas as copas do mundo, juntando gols em casa (`gols_1`) e gols como time visitante (`gols_2`).\n* Imprima o dataframe `gols` ordenado de forma decrescente, para que os times com mais gols fiquem no topo.\n\nSegue um exemplo ilustrativo com o formato do dataframe resultado:\n\n```\npa√≠s        total_gols\nBrazil      120\nArgentina   112\nGermany     107\n...\n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Criar um dataframe com os gols como time da casa (gols_1)\ngols_casa = (\n    wc[['time_1', 'gols_1']]\n    .rename(columns={'time_1': 'pa√≠s', 'gols_1': 'gols'})\n)\n\n# Criar um dataframe com os gols como time visitante (gols_2)\ngols_visitante = (\n    wc[['time_2', 'gols_2']]\n    .rename(columns={'time_2': 'pa√≠s', 'gols_2': 'gols'})\n)\n\n# Concatenar os dois dataframes\ngols_total = pd.concat([gols_casa, gols_visitante])\n\n# Agrupar por pa√≠s e somar os gols\ngols = gols_total.groupby('pa√≠s')['gols'].sum().reset_index()\n\n# Renomear a coluna com o total de gols\ngols = gols.rename(columns={'gols': 'total_gols'})\n\n# Ordenar o dataframe em ordem decrescente de total_gols\ngols = gols.sort_values(by='total_gols', ascending=False).reset_index(drop=True)\n\n# Exibir o dataframe\nprint(gols)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Q5. \nQual pa√≠s tomou mais cart√µes amarelos somando todas as copas?\n\nNeste exerc√≠cio voc√™ vai trabalhar com as colunas `cartao_amarelo_1` e `cartao_amarelo_2` onde cada observa√ß√£o √© uma string represetando uma lista dos cart√µes amarelos de um √∫nico jogo na forma `minuto|placar|jogador(a)`. Por exemplo:\n```\n['16‚Äô|1:0|Rosana G√≥mez', '20‚Äô|2:0|Gabriela Ch√°vez]\n```\n\nRecomendo criar colunas `num_cartoes_1` e `num_cartoes_2` a partir de cada coluna `cartao_amarelo_X` usando o m√©todo gen√©rico `apply` para chamar uma fun√ß√£o que voc√™ vai criar para transformar uma observa√ß√£o de cart√£o amarelo em uma contagem de elementos da lista. \n\nLembre de levar em considera√ß√£o que muitas observa√ß√µes s√£o `NaN`. \n\nEm seguida fa√ßa sua m√°gica para agrupar as informa√ß√µes por pa√≠s, acumular os cart√µes de jogos em casa e jogos visitante, e produzir o resultado final como apresentado a seguir (valores inventados):\n\n```\npa√≠s        cart√µes amarelos\nArgentina   97\nEngland     93\nAustralia   93\n...\n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\n# Fun√ß√£o para contar o n√∫mero de cart√µes amarelos em uma observa√ß√£o\ndef contar_cartoes(cartoes):\n    if pd.isna(cartoes):  # Verificar se √© NaN\n        return 0\n    return len(eval(cartoes))  # Avaliar a string como uma lista e contar os elementos\n\n# Criar colunas para contar os cart√µes amarelos de cada time\nwc['num_cartoes_1'] = wc['cartao_amarelo_1'].apply(contar_cartoes)\nwc['num_cartoes_2'] = wc['cartao_amarelo_2'].apply(contar_cartoes)\n\n# Criar dataframes para os cart√µes como time da casa e como visitante\ncartoes_casa = wc[['time_1', 'num_cartoes_1']].rename(columns={'time_1': 'pa√≠s', 'num_cartoes_1': 'cartoes'})\ncartoes_visitante = wc[['time_2', 'num_cartoes_2']].rename(columns={'time_2': 'pa√≠s', 'num_cartoes_2': 'cartoes'})\n\n# Concatenar os dataframes\ncartoes_total = pd.concat([cartoes_casa, cartoes_visitante])\n\n# Agrupar por pa√≠s e somar os cart√µes\ncartoes_agrupados = cartoes_total.groupby('pa√≠s')['cartoes'].sum().reset_index()\n\n# Renomear a coluna para o formato solicitado\ncartoes_agrupados = cartoes_agrupados.rename(columns={'cartoes': 'cart√µes_amarelos'})\n\n# Ordenar em ordem decrescente de cart√µes amarelos\ncartoes_agrupados = cartoes_agrupados.sort_values(by='cart√µes_amarelos', ascending=False).reset_index(drop=True)\n\n# Exibir o resultado\nprint(cartoes_agrupados)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Q6.\nQual o top10 jogadores com mais gols em copa? Considere gols em jogo e gols de p√™nalti.\n\nPara conseguir essa informa√ß√£o, voc√™ precisar√° trabalhar com as colunas:\n```\n10  gols_1_detalhes         \n11  gols_2_detalhes    \n14  gols_1_penalti     \n15  gols_2_penalti     \n```\n\nEssas tamb√©m s√£o colunas textuais, onde cada observa√ß√µes apresenta todos os gols de uma partida separados pelo caracter `|`. Cada gol est√° na forma `'Jogador(a) ¬∑ minuto‚Äô'`. Por exemplo:\n```\n'Alex Morgan ¬∑ 12‚Äô|Rose Lavelle ¬∑ 20‚Äô'\n```\n\nLembre de levar em considera√ß√£o que muitas observa√ß√µes s√£o `NaN`. \n\nRecomendo criar um dicion√°rio √† parte, onde cada chave ser√° um jogador encontrado nessas colunas do dataframe `wc` e o valor correspondente ser√° a contagem de ocorr√™ncias desses nomes.\n\nEm seguida basta converter o seu dicion√°rio em um dataframe e imprim√≠-lo na forma (valores n√£o s√£o inventados üòÅ):\n```\njogador(a)      num_gols \nMarta           17\nMiroslav Klose  16\n... \n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\n# Fun√ß√£o para extrair nomes dos jogadores e contar gols\ndef extrair_gols(detalhes):\n    if pd.isna(detalhes):  # Verificar se √© NaN\n        return []\n    gols = detalhes.split('|')  # Separar os gols pela barra vertical\n    jogadores = [gol.split(' ¬∑ ')[0] for gol in gols]  # Extrair o nome do jogador(a)\n    return jogadores\n\n# Criar um dicion√°rio para armazenar os gols\ngols_por_jogador = {}\n\n# Listar as colunas que cont√™m os detalhes dos gols\ncolunas_gols = ['gols_1_detalhes', 'gols_2_detalhes', 'gols_1_penalti', 'gols_2_penalti']\n\nfor coluna in colunas_gols:\n    wc[coluna] = wc[coluna].fillna('')  # Substituir NaN por string vazia\n    wc[coluna].apply(lambda x: [gols_por_jogador.update({jogador: gols_por_jogador.get(jogador, 0) + 1}) \n                                for jogador in extrair_gols(x)])\n\n# Converter o dicion√°rio em um dataframe\ngols_df = pd.DataFrame(list(gols_por_jogador.items()), columns=['jogador(a)', 'num_gols'])\n\n# Ordenar em ordem decrescente pelo n√∫mero de gols\ngols_df = gols_df.sort_values(by='num_gols', ascending=False).reset_index(drop=True)\n\n# Exibir o top 10 jogadores com mais gols\nprint(gols_df.head(10))\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}